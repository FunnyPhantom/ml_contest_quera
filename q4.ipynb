{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as tvm\n",
    "from torchvision import transforms\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train with Label 0: 10500\n",
      "train with label 1: 5500\n",
      "test images: 2000\n"
     ]
    }
   ],
   "source": [
    "def print_count_files(dir, message = None):\n",
    "    if os.path.isdir(dir):\n",
    "        file_count = sum(1 for _ in os.listdir(dir) if os.path.isfile(os.path.join(dir, _)))\n",
    "        print(f\"{message if message else dir}: {file_count}\")\n",
    "\n",
    "\n",
    "def get_all_files(dir):\n",
    "    if os.path.isdir(dir):\n",
    "        files = []\n",
    "        for root, directories, filenames in os.walk(dir):\n",
    "            for filename in filenames:\n",
    "                files.append(os.path.join(root, filename))\n",
    "        return files\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "dirs = [\"./q4/patch_camelyon/train/0\", \"./q4/patch_camelyon/train/1\", \"./q4/patch_camelyon/test\",]    \n",
    "msgs = [\"train with Label 0\", \"train with label 1\", \"test images\"] \n",
    "\n",
    "for dir, msg in zip(dirs, msgs):\n",
    "    print_count_files(dir, msg)\n",
    "\n",
    "\n",
    "image_lists = [get_all_files(x) for x in dirs]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sut-default-env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/sut-default-env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "base_resin = tvm.resnet50(pretrained=True)\n",
    "base_resin = torch.nn.Sequential(*list(base_resin.children())[:-1])\n",
    "\n",
    "for p in base_resin.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "loading 0th image\n",
      "loading 100th image\n",
      "loading 200th image\n",
      "loading 300th image\n",
      "loading 400th image\n",
      "loading 500th image\n",
      "loading 600th image\n",
      "loading 700th image\n",
      "loading 800th image\n",
      "loading 900th image\n",
      "loading 1000th image\n",
      "loading 1100th image\n",
      "loading 1200th image\n",
      "loading 1300th image\n",
      "loading 1400th image\n",
      "loading 1500th image\n",
      "loading 1600th image\n",
      "loading 1700th image\n",
      "loading 1800th image\n",
      "loading 1900th image\n"
     ]
    }
   ],
   "source": [
    "def health_check(msg, i, threshold = 100):\n",
    "    if (i % threshold == 0):\n",
    "            print(msg)\n",
    "\n",
    "def image_cleanup(image_list):\n",
    "    images = []\n",
    "    for (i, image_path) in enumerate(image_list):\n",
    "        health_check(f\"loading {i}th image\", i)\n",
    "        image = Image.open(image_path)\n",
    "        image.convert(\"RGB\")\n",
    "        # print(image_path)\n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "    feats = []\n",
    "    with torch.no_grad():\n",
    "        for (i, img) in enumerate(images):\n",
    "            health_check(f\"extracting {i}th image features\")\n",
    "            img = img.unsqueeze(0)\n",
    "            feature = base_resin(img)\n",
    "            feature = feature.squeeze().numpy()\n",
    "            feats.append(feature)\n",
    "\n",
    "    n_clusters = 2\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    labels = km.fit_predict(feats)\n",
    "\n",
    "    # Determine the cluster with the lower number of items\n",
    "    label_counts = np.bincount(labels)\n",
    "    lower_cluster_label = np.argmin(label_counts)\n",
    "\n",
    "    # Get the names of images assigned to the lower cluster label\n",
    "    assigned_images = [image_list[i] for i, label in enumerate(labels) if label == lower_cluster_label]\n",
    "\n",
    "    return assigned_images\n",
    "\n",
    "print(len(image_lists[2]))\n",
    "image_cleanup(image_lists[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sut-default-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
